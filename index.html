<html>
<head>
    <link rel="stylesheet" href="style.css">
    <title>Cooperative Data Mining</title>
    </head>
<body>
    <center>
    <h1>INTRODUCTION</h1>
    </center>

    <p> 71.   This paper describes the ViziMine data mining tool used to visualize the cooperative
data mining process. The aim of the ViziMine tool is twofold: First, the knowledge, as
discovered by the individual tools, is visualized throughout the data mining process and
presented in the form of comprehensible rules; this aspect includes visualization of the
results of data mining as well as the cooperative learning process. Second, the data are
visualized prior to and during cooperative data mining. In this way, the quality of the data
can be assessed throughout the knowledge discovery process, which includes data
preprocessing, data mining, and reporting. During data mining, the visualization of data
as covered by individual rules shows the portion of the data covered. The visual data
mining process is interactive in that humans are able to adapt the results and data during
mining. In addition, this chapter shows how virtual reality can be used to visualize the
data and its descriptors.
The chapter is organized as follows: The next section introduces the cooperative
inductive learning team (CILT) data mining system in which two or more data mining tools
co-exist. An overview of current trends in visual data mining follows. The next section
discusses the ViziMine system, which incorporates visual data mining components into
the CILT system. Then we introduce the use of three-dimensional visualization, virtual
reality-based visualization and multimedia data mining, which may be used to visualize
the data used for data mining. Conclusions are presented in the last section of the
chapter.</p>


<br>

    <center>
<h1>COOPERATIVE DATA MINING</h1>
    </center>
        <p>  Data mining concerns the automated discovery of hidden patterns and relationships that may not always be obvious. A number of data mining tools exist, including
decision trees, rule induction programs and neural networks (Han & Kamber, 2001). Each
of these tools applies a specific algorithm to the data in order to build a model based on
the statistically significant relationships found in the data.
A number of data mining practitioners have found that, when supplied with the same
data repository, different data mining tools produce diverse results. This fact is due to
the so-called inductive bias that each algorithm uses when constructing the model
(Mitchell, 1997). That is, each data mining tool uses a different learning style (based on
one of a variety of different statistical measures) and criteria when building its model. The
purpose of combining the results of diverse data mining tools, through the fusion thereof,
is to produce high quality results. Therefore, the development of a hybrid multi-strategy
learning system that incorporates more than one learning style is currently an active area
of research (Honavar, 1995; Lin & Hendler, 1995; Sun, 1995). In this multi-strategy
learning approach, the strengths of each technique are amplified, and the weaknesses
are ameliorated.
In the CILT system, two or more diverse data mining techniques are combined into
a multi-strategy learning system (Viktor, 1999). The system currently includes three
different data mining tools with different knowledge representations. The C4.5 tool
constructs a decision tree using the information gain ratio criteria (Quinlan, 1994). This
tree is pruned to produce a set of rules. The CN2 method induces rules from examples
using the Laplace error estimate (Clark & Niblett, 1989). Third, the ANNSER learner.
            
           <br><br>
            
        
       72.   creates rules from a trained neural network (Viktor, Engelbrecht, & Cloete, 1998). In
addition, the rules of the domain expert are included through a personal assistant (PA)
learner, which contains a knowledge base constructed after interviews with one or more
domain experts (Viktor, 1999). That is, the user plays an active role in the data mining
process, and is able to make and implement decisions that will affect its outcome (Hinke
& Newman, 2001).
In the CILT system, the individual results are fused into one through a three-phase
process, as follows (Viktor, 1999; Viktor, le Roux, & Paquet, 2001):
            <br>
            
Phase 1: Individual learning. First, each individual data mining tool (or learner) uses a
training set to form an initial representation of the problem at hand. In addition, the
results of the user, a domain expert, are modeled as part of the system (Viktor, 1999).
Each individual component’s knowledge is stored in a separate knowledge base,
in the form of disjunctive normal form (DNF) rules.
            <br>
            
Phase 2: Cooperative learning. During phase 2, the individual data mining tools share
their knowledge with one another. A rule accuracy threshold is used to distinguish
between low- and high-quality rules. Cooperative learning proceeds in four steps
as follows (Viktor, le Roux, & Paquet, 2001):
            
            <br>
1) each data mining tool queries the knowledge bases of the others to obtain the
high-quality rules that it may have missed. These rules are compared with the
rules contained in its rule set. In this way, a NewRule list of relevant rules is
produced.
            
            <br>
            
            
2) the NewRule list is compiled by identifying the following relationships
between the rules, where R1 denotes a high-quality rule contained in the
tool’s rule set and R2 denotes a high-quality rule created by another data
mining tool.
• Similarities. Two rules, R1 and R2, are similar if two conditions hold:
the training examples covered by rule R1 are a subset of those covered
by R2; andthe rules contain the same attributes with similar values. For
example, the attribute-value test (petal-width > 49.0) is similar to the test
(petal-width >49.5). If R1 and R2 are similar, it implies that the learner
has already acquired the knowledge as contained in rule R2 and that R2
should not be added to the NewRule list.
• Overlapping rules. Two rules overlap when they contain one or more
attribute-value tests that are the same. For example, rule Rl with
attribute-value tests (petal-length > 7.5) and (petal-width < 47.5) and
rule R2 with attribute-value tests (petal-length > 7.5) and (sepal-length
< 35.5) overlap. Rule R2 is placed on the tool’s NewRule list. Note that,
for the example, a new rule R3 with form (petal-length > 7.5) and petalwidth < 47.5) and (sepal-length < 35.5)} may be formed. This rule
represents a specialization that will usually be less accurate than the
original general rules and will cover fewer cases. Such a specialization
should be avoided, since it leads to overfitting.
• Subsumption. A rule R2 subsumes another Rl if and only if they
describe the same concept and the attribute-value tests of R2 form a
subset of that of rule Rl. In other words, rule R2 is more general than
R1. If R2 subsumes rule Rl, it is placed on the NewRule list. 
    
    <br><br>
    
  73.   3) the rule combination procedure is executed. Here, the rules as contained in
the NewRule list are used to form new rules, as follows. The attribute-value
tests of the rules as contained in the NewRule list are combined with the
attribute-value tests of the rules in the tools rule set to form a new set of rules.
Each of these new rules is evaluated against the test set. The new high-quality
rules, which are dissimilar to, do not overlap with, and are not subsumed by
existing rules, are retained on the NewRule list. These rules act as input to the
data generation step.
    
    <br>
    
4) the data generator uses each of the rules in the NewRule list to generate a new
set of training instances. The newly generated training instances are added
to the original training set, and the learner reiterates the individual learning
phase. In this way, a new training set that is biased towards the particular rule
is generated. This process is constrained by ensuring that distribution of the
data as contained in the original training set is maintained. Interested readers
are referred to Viktor (1999) for a detailed description of this process.
Steps 1 to 4 are reiterated until no new rules can be generated. Lastly, redundant
rules are pruned using a reduced error pruning algorithm.
    
    <br>
    
Phase 3: Knowledge fusion. Finally, the resulting knowledge, as contained in the
individual knowledge bases, is fused into one. Again, redundant rules are pruned
and a fused knowledge base that reflects the results of multi-strategy learning is
created.
     
Note that a detailed description of the cooperative learning approach falls beyond
the scope of this paper. Interested readers are referred to Viktor (1999) for a description
thereof. This chapter concerns the visual representation of the cooperative data mining
process and results, as well as the data itself, using visual data mining techniques, as
discussed next.
    VI</35.5)></47.5)></p>
            

<br>
            <center>
            <h1>VISUAL DATA MINING</h1>
    </center>
            <p>Data mining techniques, as discussed above, construct a model of the data through
repetitive calculation to find statistically significant relationships within the data.
However, the human visual perception system can detect patterns within the data that
are unknown to a data mining tool (Johnson-Laird, 1993). The combination of the various
strengths of the human visual system and data mining tools may subsequently lead to
the discovery of novel insights and the improvement of the human’s perspective of the
problem at hand.
                
                <br>
                
Data mining extracts information from a data repository of which the user may be
unaware. Useful relationships between variables that are non-intuitive are the jewels that
data mining hopes to locate. The aim of visual data mining techniques is thus to discover
and extract implicit, useful knowledge from large data sets using data and/or knowledge
visualization techniques. Visual data mining harnesses the power of the human vision
system, making it an effective tool to comprehend data distribution, patterns, clusters,
and outliers in data (Han & Kamber, 2001).
                
                <br><br>
                
                
          74.   Visual data mining integrates data visualization and data mining and is thus closely
related to computer graphics, multimedia systems, human computer interfaces, pattern
recognition, and high performance computing. Since there are usually many ways to
graphically represent a model, the type of visualizations used should be chosen to
maximize their value to the user (Johnson-Laird, 1993). This requirement implies that we
understand the user’s needs and design the visualization with the end user in mind.
                
                <br>
                
Note that, in order to ensure the success of visualization, the visual data mining
process should be interactive. In interactive visual data mining, visualization tools can
be used to help users make smart data mining decisions (Docherty & Beck, 2001; Han &
Kamber, 2001). Here, the data distribution in a set of attributes is displayed using color
sectors or columns, giving the user the ability to visually understand the data and
therefore allowing him or her to be interactively part of the mining process. In the CILT
environment, the user participates (through the PA learner) in the cooperative process
and is therefore able to validate the knowledge, as well as add his personal knowledge
to the process.
                
                <br>
                
The following observation is noteworthy. Visual data mining concerns both
visualizing the data, and visualizing the results of data mining and the data mining
process itself. In a cooperative data mining environment, as introduced in the last
section, result visualization includes the interactive visualization of the results of
multiple data mining techniques and the cooperation processes. Data visualization is
important not only during data mining, but also during data preprocessing, as discussed
next.
</p>
            <center>
            <h2>Data Visualization During Data Preprocessing</h2>
    </center>
            
            <p>Data preprocessing is one of the most important aspects of any data mining exercise.
According to Adriaans and Zantinge (1996), data preprocessing consumes 80% of the
time of a typical, real-world data mining effort. Here, the “garbage-in, garbage-out” rule
applies. According to a survey conducted by Redman (1996), a typical operational data
repository contains 1% to 5% incorrect values. It follows that the poor quality of data
may lead to nonsensical data mining results, which will subsequently have to be
discarded. In addition, the implicit assumption that the data do in fact relate to the case
study from which they were drawn and thus reflect the real world is often not tested (Pyle,
1999).
                
                <br>
                
Figure 1 shows the different components of the knowledge discovery process,
which includes the selection of appropriate tools, the interpretation of the results, and
the actual data mining itself. Data preprocessing concerns the selection, evaluation,
cleaning, enrichment, and transformation of the data (Adriaans & Zantinge, 1996; Han
& Kamber, 2001; Pyle, 1999). Data preprocessing involves the following aspects:
                <br>
                
• Data cleaning is used to ensure that the data are of a high quality and contain no
duplicate values. If the data set is large, random samples are obtained and analyzed.
The data-cleaning process involves the detection and possible elimination of
incorrect and missing values. Such values may have one of a number of causes.
These causes include data capturing errors due to missing information, deliberate
typing errors, and negligence. Moreover, end users may fraudulently supply
misleading information. 
                
              <br><br>
    
            
    <center>
            <p>  75.  Figure 1: Data preprocessing and data mining tasks [Adapted from Docherty & Beck,
                2001].</p>
            <br>
            
            
            <img src="imagepdf.png">
    </center>
            
            <br>
            
            <p>• Data integration. When integrating data, historic data and data referring to dayto-day operations are merged into a uniform format. For example, data from source
A may include a “date of recording” field, whereas the data from source B implicitly
refer to current operations.
                
                <br>
                
• Data selection involves the collection and selection of appropriate data. Highquality data collection requires care to minimize ambiguity, errors, and randomness
in data. The data are collected to cover the widest range of the problem domain.
                
                <br>
                
• Data transformation involves transforming the original data set to the data
representations of the individual data mining tools. Neural networks, for example,
use numeric-valued attributes, while decision trees usually combine numeric and
symbolic representations. Care should be taken to ensure that no information is lost
during this coding process.
                
                <br>
                
Data visualization provides a powerful mechanism to aid the user during the
important data preprocessing steps (Foong, 2001). Through the visualization of the
original data, the user can browse to get a “feel” for the properties of that data. For
example, large samples can be visualized and analyzed (Thearling et al., 2001). In
particular, visualization can the used for outlier detection, which highlights surprises in
the data, that is, data instances that do not comply with the general behavior or model
of the data (Han & Kamber, 2001; Pyle, 1999). In addition, the user is aided in selecting
the appropriate data through a visual interface. During data transformation, visualizing
the data can help the user to ensure the correctness of the transformation. That is, the
user may determine whether the two views (original versus transformed) of the data are
equivalent. Visualization may also be used to assist users when integrating data sources,
assisting them to see relationships within the different formats.  
                
                <br>
                
                Copyright © 2003, Idea Group Inc. 
                Copying or distributing in print or electronic forms without written
permission of Idea Group Inc. is prohibited.</p>
    </body>
    </html>